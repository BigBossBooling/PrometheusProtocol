# Prometheus Protocol: Core Execution Logic Concepts

This document outlines the conceptual framework for how `PromptObject` instances and `Conversation` flows within the Prometheus Protocol are processed and interact with a hypothetical AI engine, referred to as "Google Jules" (or simply "Jules").

## I. Goals of Execution Logic Conceptualization

1.  **Define Interaction Blueprint:** Outline the data flow and structural components required to send a well-formed prompt (derived from `PromptObject`) to Jules and receive a structured response.
2.  **Structure AI Responses:** Define a standardized way to represent the AI's output within Prometheus Protocol, including both the content and relevant metadata.
3.  **Conceptualize Conversation Management:** Describe how a sequence of turns in a `Conversation` object would be executed, including the management of conversational context/history passed to Jules.
4.  **Consider Basic Error Handling:** Acknowledge potential errors during AI interaction and how they might be captured.
5.  **Lay Groundwork for UI:** Provide a basis for how AI execution and responses would be initiated and displayed within the user interface concepts.

## II. Scope for V1 Concepts

For this initial conceptualization (V1 Concepts), the focus will be on:

1.  **Single `PromptObject` Execution:** Detailing the process for a standalone prompt.
2.  **Linear `Conversation` Execution:** Describing the turn-by-turn execution of a predefined, linear sequence of `PromptTurn` objects. Branching logic based on `PromptTurn.conditions` will be mentioned conceptually but not fully detailed for V1 execution flow.
3.  **Hypothetical "Jules API" Contract:** Defining a plausible request and response structure for interacting with Jules. This is a necessary abstraction as we are not integrating with a real, specific API at this conceptual stage.
4.  **Core Data Structures:** Defining necessary Python data classes (like `AIResponse`) to handle data internally.
5.  **Conceptual `JulesExecutor` Class:** Describing a class responsible for orchestrating the interaction with the hypothetical Jules API.
6.  **Basic Context Management:** Simple approaches to passing conversational history between turns.

**Out of Scope for V1 Concepts (Future Considerations):**

*   **Real-time/Streaming Responses:** Handling responses as they are generated by Jules. V1 assumes a complete response is received.
*   **Advanced AI Tool Use:** Mechanisms for Jules to call external tools or functions during its processing.
*   **Complex Error Recovery Strategies:** Sophisticated retries, fallbacks, or user interventions for AI errors.
*   **Dynamic Function Calling/Orchestration:** Complex runtime decisions beyond simple linear or conditional turn execution.
*   **Performance Optimization:** Detailed strategies for minimizing latency or cost of Jules API calls.

---
*Next sections will detail the Hypothetical "Jules API", `AIResponse` Data Class, `JulesExecutor` Class, Conversation Execution Flow, and UI updates.*

## III. Hypothetical "Jules API" Contract

To conceptualize the execution logic, we need to assume an API contract with the "Google Jules" AI engine. This is a hypothetical definition for our planning purposes. We'll assume it's a JSON-based HTTP API.

### A. Jules Request Structure

A request to the Jules API to generate content would conceptually look like this:

**Endpoint (Conceptual):** `POST /api/v1/generate`

**Request Body (JSON Example):**
```json
{
  "api_key": "USER_API_KEY_HYPOTHETICAL",
  "request_id_client": "client_generated_uuid_for_tracking", // Optional: client can send an ID
  "prompt_payload": {
    "role": "You are a helpful assistant specialized in astrophysics.",
    "task_description": "Explain the concept of a black hole in simple terms suitable for a high school student.",
    "context_data": "The student has basic knowledge of gravity but no advanced physics background.",
    "constraints_list": [
      "Keep the explanation under 200 words.",
      "Avoid complex mathematical formulas.",
      "Use an analogy if possible."
    ],
    "examples_list": [
      "User: What is a star? -> AI: A star is a giant ball of hot gas that produces light and heat through nuclear fusion."
    ],
    "settings": { // Hypothetical model parameters
      "temperature": 0.7,
      "max_tokens": 250,
      "creativity_level_preference": "balanced" // Could map to temperature or other settings
    }
  },
  "conversation_history": [ // Optional: Used for multi-turn conversations
    {"speaker": "user", "text": "What's the closest black hole to Earth?"},
    {"speaker": "ai", "text": "The closest black hole currently known is Gaia BH1, located about 1,560 light-years away."}
  ],
  "user_preferences": { // Optional: User-level settings
      "output_language_preference": "en-US"
  }
}
```

**Key components of the Request:**
*   `api_key`: For authentication (hypothetical).
*   `request_id_client`: An optional ID the client can send for its own tracking.
*   `prompt_payload`: Contains the core elements derived from our `PromptObject`.
    *   `role`, `task_description`, `context_data`, `constraints_list`, `examples_list`: Directly map from `PromptObject`.
    *   `settings`: A dictionary for model-specific parameters like temperature, max tokens, etc. Prometheus Protocol could store preferred settings per prompt or globally.
*   `conversation_history`: An optional list of previous turns, each marked with `speaker` ("user" or "ai") and `text`. This is crucial for providing context in multi-turn dialogues.
*   `user_preferences`: Optional user-level settings that might influence generation.

### B. Jules Response Structure

Jules would respond with a JSON object.

**Success Response (JSON Example):**
```json
{
  "status": "success",
  "request_id_client": "client_generated_uuid_for_tracking", // Echoed back if provided
  "request_id_jules": "jules_generated_uuid_for_this_request", // Jules's own ID for the request
  "response_data": {
    "content": "A black hole is a region in space where gravity is so strong that nothing, not even light, can escape. Imagine it like a cosmic vacuum cleaner, but way more powerful. It forms when a very massive star collapses in on itself. While you can't see a black hole directly, scientists can detect its presence by observing its effects on nearby stars and gas.",
    "tokens_used": 152,
    "finish_reason": "stop", // e.g., "stop" (completed naturally), "length" (hit max_tokens), "content_filter"
    "quality_assessment": { // Hypothetical advanced feedback from Jules
        "clarity_score": 0.85,
        "relevance_score": 0.92
    }
  },
  "debug_info": { // Optional, for diagnostics
    "model_used": "jules-xl-v2.3-apollo",
    "processing_time_ms": 1234
  }
}
```

**Error Response (JSON Example):**
```json
{
  "status": "error",
  "request_id_client": "client_generated_uuid_for_tracking",
  "request_id_jules": "jules_generated_uuid_for_this_request",
  "error": {
    "code": "JULES_ERR_CONTENT_POLICY_VIOLATION", // Standardized error code
    "message": "The generated content was blocked due to a content policy violation.",
    "details": "Further information about the violation if applicable."
  }
}
```
Or for an API error:
```json
{
  "status": "error",
  "error": {
    "code": "AUTH_FAILURE",
    "message": "Invalid API key."
  }
}
```

**Key components of the Response:**
*   `status`: "success" or "error".
*   `request_id_client`: Echoed from the request for client-side matching.
*   `request_id_jules`: Jules's internal ID for the request.
*   `response_data` (on success):
    *   `content`: The main AI-generated text.
    *   `tokens_used`, `finish_reason`: Common LLM metadata.
    *   `quality_assessment`: Hypothetical scores Jules might provide.
*   `error` (on error):
    *   `code`: A standardized error code from Jules.
    *   `message`: A human-readable error message.
    *   `details`: Optional further information.
*   `debug_info`: Optional diagnostic information.

This hypothetical API contract provides a basis for designing the `JulesExecutor` and `AIResponse` data class.

---
*Next section: `AIResponse` Data Class.*

## V. Conversation Execution Flow (Conceptual V1)

This section describes how a `Conversation` object, composed of multiple `PromptTurn` instances, would be executed sequentially using the `JulesExecutor`. For V1, we assume a linear progression of turns.

### A. Orchestrating Process

A higher-level process or function, let's call it `run_conversation_flow`, would be responsible for managing the execution of a `Conversation`. This process would likely:
1.  Initialize a `JulesExecutor` instance.
2.  Take a `Conversation` object as input.
3.  Maintain a `current_conversation_history` list.
4.  Store all `AIResponse` objects generated during the flow.

### B. Turn-by-Turn Execution Loop

The `run_conversation_flow` process would iterate through the `Conversation.turns` list (which is assumed to be ordered):

1.  **Initialize `current_conversation_history`:** Start as an empty list: `List[Dict[str, str]]`. This list will store `{"speaker": "user" | "ai", "text": "..."}` entries.

2.  **For each `PromptTurn` in `Conversation.turns`:**
    *   **a. (Future V2 - Conditional Logic): Check `turn.conditions`:**
        *   Conceptually, if `turn.conditions` are present (e.g., `{"previous_ai_response_contains": "keyword"}`), evaluate these conditions against the content of the *previous* turn's `AIResponse`.
        *   If conditions are not met, this turn might be skipped. The UI would need to reflect this skipped status.
        *   **For V1 conceptualization, assume all turns are executed sequentially without conditions.**

    *   **b. Execute the Turn:**
        *   Call `jules_executor.execute_conversation_turn(turn, current_conversation_history)`.
        *   This returns an `AIResponse` object for the current turn.
        *   The `AIResponse` object should have its `source_conversation_id` field populated with the ID of the `Conversation` being executed. This would likely be done by the `run_conversation_flow` orchestrator before or after receiving the response from the executor.

    *   **c. Store the `AIResponse`:** Associate this `AIResponse` with the current `PromptTurn` (e.g., in a dictionary mapping `turn_id` to `AIResponse`).

    *   **d. Update `current_conversation_history`:**
        *   **User's Turn:** Append the user's contribution for the current turn to the history. For V1 simulation and simplicity, the `turn.prompt_object.task` is a reasonable representation of the user's directive for that turn.
            *   *Conceptual Note:* A more complete representation for the "user" turn in history could eventually include a summary of role/context if they significantly change and are meant to be "spoken" or "established" as part of that turn's input to the AI. However, for typical chat history, the primary new instruction/query (`task`) is key.
            ```
            current_conversation_history.append({
                "speaker": "user",
                "text": turn.prompt_object.task
            })
            ```
        *   **AI's Turn:**
            *   If the AI execution was successful (`ai_response.was_successful` is True and `ai_response.content` is not None):
                ```
                current_conversation_history.append({
                    "speaker": "ai",
                    "text": ai_response.content
                })
                ```
            *   If the AI execution was **not** successful (`ai_response.was_successful == False`):
                *   For V1, we will **not** add an entry for the AI's response to the `current_conversation_history`. The error is captured in the `AIResponse` object for that turn and should be handled by the orchestrator (e.g., potentially halting the conversation, logging the error). Adding AI error messages directly into the *history sent to Jules for subsequent turns* might confuse the AI or lead to undesirable cascading error discussions. The focus of the history is the successful dialogue flow.
                *   The UI should still clearly indicate that an error occurred for this turn, using the `AIResponse.error_message`.

    *   **e. Handle AI Errors:**
        *   If `ai_response.was_successful` is False, the `run_conversation_flow` might:
            *   Log the error.
            *   Decide whether to halt the conversation or attempt to proceed (V1: likely halt or mark subsequent turns as "not executed").
            *   The UI would need to reflect that an error occurred on this turn.

3.  **Completion:** After iterating through all turns (or halting due to an error), the `run_conversation_flow` would return the collection of `AIResponse` objects, perhaps along with the final conversation history.

### C. Context Management

*   The `current_conversation_history` list is the primary mechanism for context management in this V1 concept. It's passed with each call to `JulesExecutor.execute_conversation_turn`.
*   Jules (hypothetically) uses this history to understand the dialogue flow and generate contextually appropriate responses for subsequent turns.
*   The history could grow large. Future considerations (V2+) might involve summarization techniques or more sophisticated context window management if the hypothetical Jules API has token limits for history.

This flow provides a basic but functional way to execute a linear sequence of prompts as a conversation, capturing each interaction's result.

---
*Next section: UI Concepts for Execution and Response Display.*
